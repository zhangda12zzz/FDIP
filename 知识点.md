## 2025-7-2

1、pycharm 科学模式变成了   pycharm plot

2、进度条设置 leave   **运行完是否删除这个进度条**

3、 print 和 tqdm 有可能出现先实现顺序的问题

4、epoch少的时候的训练集的loss有可能低于val的loss，因为训练的时候有惩罚项 

5、epoch 先设置大一点，然后看tensorBoard观察曲线什么时候平稳。 

**（进阶）实现早停**：
 虽然你的代码里没有，但一个完整的训练流程通常会加入早停逻辑。你可以在验证循环后添加类似这样的逻辑：

#### 进阶：

**早停（Early Stopping）**: 判断验证损失是否不再下降，从而决定何时停止训练。

**模型选择（Model Selection）**: 比较不同模型的优劣。

**超参数调整（Hyperparameter Tuning）**: 根据验证损失来调整学习率等参数。



### 2025-07-03

**处理时序序列时：（填充+掩码+分桶）：** 这是处理变长序列最标准、最强大的方法。它能最大程度地保留数据中的宝贵信息。虽然实现起来比方案一稍微复杂一点，但几乎所有的深度学习框架（PyTorch, TensorFlow）都有现成的函数（如 `pad_sequence`）和成熟的教程来帮助你实现。这是最值得投入时间学习的正确方向。



远程控制软件是在**被控电脑本地抓取画面** → 编码 → 传输 → 控制端解码显示。

> 所以，被控端的**屏幕分辨率决**定了抓取的图像源大小（清晰度基础

**编码压缩会影响画质**

**远程协助画质 = 被控电脑分辨率 × 编码压缩效果 × 网络带宽 × 控制端缩放表现**

1-在 GitHub 上创建一个新的仓库

2-初始化 Git 仓库

3- git config --global user.name "Your Name"
git config --global user.email "your_email@example.com"

4- git add .  git commit -m ""  git remote add origin https://github.com/username/repository.git

git remote -v   git push -u origin main

5- 修改更换远程仓库地址  git remote set-url origin https://github.com/new_username/new_repository.git

6- 


**产生公钥命令： ssh-keygen -t ed25519 -C "your_email@example.com"**

**git remote add origin git@github.com:your_username/your_repo.git**

**git push -u origin main**

git remote set-url origin git@github.com:your_username/your_repo.git

**git push**

## 2025-07-04

**MSFKE 创新点：**

1. **BranchAwareSEModule**

   * **分支感知的 SE 设计**：对每条频率分支分别做独立的通**道注意力（SE）**，并在分支间再做一次全局**重要性重标定**。
   * **阶段感知 (stage-aware)**：根据「early/mid/late」阶段，动态调整 Dropout 比例和不同频段的偏置 `freq_bias`，从而在训练**早期更关注全局低频、中期平衡、后期聚焦高频**细节。
   * **躯干 vs 肢体差异化**：`module_type='trunk'` 偏好低频，使用大卷积核；`module_type='limb'` 偏好高频，使用小卷积核并切换到 GELU 激活。

2. **TrunkSEModule & LimbSEModule**

   * **去全局池化的轻量化 SE**：用 1×1 卷积替代全局池化 + 全连接，直接在时序维度上的特征图里做压缩–扩张，计算更紧凑。
   * **定制化卷积**：Trunk 用宽感受野 (kernel\_size=5)，Limb 用深度可分离 (groups=channels) 卷积，分别强化全局与局部信息捕捉。

3. **NodeAwareMSFKE（节点感知的多尺度频域特征提取）**

   * **多尺度分支提取**：对每个节点并行应用一**组不同膨胀率（dilation）**的双卷积分支，形成多频段特征。
   * **节点专属 SE**：每个节点都配一对 `BranchAwareSEModule`（trunk/limb），实现 per-node 的多频融合与注意力加权。
   * **节点位置编码融合**：为每个节**点学习可训练 embedding**，并在 SE 输出后拼接到特征里，强化「关节身份」信息。
   * **阶段可变架构**：根据训练阶段 (`stage=early/mid/late`) 动态选取膨胀率列表及基础通道数，保证不同训练阶段对全局 vs 细节的侧重点。

4. **稀疏掩码（Mask）支持**

   * 虽未直接写出，但在高层调用中可引入 mask，将仅有的 6 个叶节点数据有效化，屏蔽其余 18 个全零通道，达到跳过无效计算、节省 FLOPs、加速收敛的目的。

### DFTFPE
### 1. 图时空卷积网络 (SpatioTemporalGCN)

1. **阶段感知的图结构选择**

   * 根据 `stage=early/mid/late` 动态切换不同的骨骼拓扑 (`Graph_B` vs `Graph_A`)、节点数（6 vs 24）和是否需要由 IMU → 全关节的映射层，兼顾训练早期**轻量化与中后期全骨骼建模**。
2. **可学习的边重要性 (Edge Importance)**

   * 在固定的邻接矩阵 `A` 上引入可训练参数 `edge_importance`，使模型能**自适应地微调骨骼关节间的消息传递强度**。
3. **双层图卷积 + 序列级残差**

   * 两层 `GraphConvBlock` 串联，每层内**部自带残差分支**，并在时序与节点维度上均做批量归一化，增强深度可训练性。
4. **统一时序–节点并行到串行处理**

   * 先用 GCN 在 `[B, T, N, C]` 上并行提取空间依赖，再 reshape→`TemporalConvBlock` 在 `[B, C·N, T]` 上做时间卷积，保证时空信息全面融合。

---

### 2. 非对称双向 GRU (AsymmetricBidirectionalGRU)

1. **窗口中心化滑动**

   * 对每个时间点构造一个以“当前帧”为中心的不对称窗口，**前向 GRU 覆盖过去更多帧，后向 GRU 聚焦未来较少帧**，更符合动作预测的因果性质。
2. **矢量化高性能实现**

   * 利用 `F.pad`+`unfold`一次性抽取所有滑窗，并在批次维度上并行跑前/后向 GRU，大幅提升对齐和吞吐。
3. **可调节的阶段超参**

   * 不同 `stage` 下动态设置窗口长度、当前帧索引、丢弃率和滑动步长，**为不同训练阶段提供粗→细、慢→快的时序建模策略**。

---

### 3. 自定义温度缩放多头注意力 (CustomMultiheadAttention)

1. **可控注意力“锐化”/“平滑”**

   * 在标准点积注意力里加入**温度参数** `temperature`，数值越高分布越平滑（early stage），越低分布越集中（late stage），让网络按阶段动态调整关注范围。
2. **纯 PyTorch 实现、Batch-First 优化**

   * 整段代码从投影到 reshape，再到 softmax/dropout，均基于 `batch_first=True`，与后续融合层无缝衔接。

---

### 4. 双流 Transformer 融合 (DSTFPE → DualStreamTransformerFusion)

1. **并行“躯干” vs “肢体”流**

   * `body_feats`（GCN 全局特征）和 `limb_feats`（GRU 局部特征）分别过**自注意力 → 交叉注意力**，保留双流特有语义。
2. **交叉融合门控**

   * 对每次交叉注意力输出，用小型门控网络学习“是保留自身流”还是“借用对方流”更多信息，实现自适应特征混合。
3. **阶段映射 → 融合温度**

   * 在 `DSTFPE` 顶层用字典把 `stage` 映射到注意力温度值，贯穿整个多层双流 Transformer，形成完整的“粗→细”训练节奏。

---


## 回归问题可以用到的图

1. **预测值 vs. 真实值 散点图**

2. ** 残差图**

3. **残差分布直方图、KDE\Q-Q图**

4. **特征相关性或重要性热力图**<训练阶段>

5. **网格热图**在二维特征空间中，用色块展示模型预测或误差大小<训练阶段>

## 2025-07-04

git

<pre> 
<<<<<<< HEAD
// 本地版本的内容
=======
// 远程版本的内容
>>>>>>> origin/main
</pre>


### windows账户问题

**注册表可以解决**
<pre>删除  IdentityCRL</pre>


#### scheduler.step()在optimizer.step()之后

**non_blocking=True 是一个用于 异步数据传输 的**

## 2025-07-14

1. **dropout 本身不减少参数量**

 **dropout 训练会带来额外的内存和计算开销, 框架分配掩码（mask） 和临时张量  (flops增加)
 dropout 在推理时被关闭，(影响较小)**

2. **flops和数据集没管（一次计算次数）一次输入的形状有关**

3. 小batch size：梯度估计噪声更大，但这种噪声有时有助于逃出局部最优，**泛化性能**可能更好  (多样化数据适合)

   大batch size：梯度估计**更稳定准确**，但可能陷入尖锐的局部最优，**泛化性能可能稍差**  (结构化数据适合)
   
   **一般先选择硬件能支持的最大batch size**

4. **直接的减少推理FLOPs的方法：**   
   剪枝（pruning）：直接减少参数和计算量
   
   量化（quantization）：减少每个操作的计算复杂度
   
   知识蒸馏：训练更小的模型
   
   架构优化：
   
   使用更高效的激活函数（如ReLU vs. GELU）
   
   减少层数或隐藏单元数
   
   使用深度可分离卷积等高效结构

5. 剪枝----（通常是在「训练结束后」才运行的）----【损失精度】

**让一部分权重 = 0 ----FLOPs 理论上按比例下降（稀疏矩阵乘法）**     【P32 → FP16（或 BF16） ：FLOPs 数量本身不变、内存少】


6. **量化**

将模型参数从高精度（如FP32）转换为低精度（如INT8、INT4）

7. **蒸馏**   <训练阶段>

用大模型（教师）指导小模型（学生）的训练过程    **【通常改变模型结构（变小）】**

已训练好的大模型作为教师、重新训练小模型（学生）

## 2025-07-15

数据量 <10000 小      10000-10万    中

###### git

.git/ 目录下的核心文件    作用：存储仓库的所有元数据（版本历史、分支、配置等）

.gitignore   作用：声明不被 Git 跟踪的文件模式（如编译产物、日志）


**可分离卷积**      减少计算量、把卷积分成两步骤

**MBConv 包含可分离卷积的深度卷积部分**


`指标	FLOPs	参数量（Parameters）
含义	模型前向推理的浮点运算总次数	模型中可训练参数的总数量
计算方式	与输入大小相关（如卷积核滑动计算）	仅取决于模型结构（如权重矩阵形状）
典型影响	决定计算速度和能耗	影响内存占用和存储需求
相关性	通常参数量大的模型FLOPs也高，但并非绝对`

**卷积操作比线性层flops 低**           维度尽量不用线性层

## 2025-07-26

### 知识蒸馏

在大型教师模型（Teacher Model）训练完成后，将其知识（如输出层的软标签、中间特征等）迁移到小型学生模型（Student Model）

**步骤：**
**常见 ：**  先独立训练教师模型。    固定教师模型，用其输出的软标签（Soft Targets）或中间特征指导学生模型的训练。

自蒸馏（Self-Distillation）：同一模型同时作为教师和学生，通过历史检查点或不同分支提供知识。

### 渐进式剪枝

<pre>
初始化训练：正常训练一个基准模型（未剪枝）。

迭代剪枝：

   剪枝阶段：按一定策略（如权重大小、梯度重要性）移除部分参数。
   
   微调阶段：对剪枝后的模型进行微调，恢复性能。

终止条件：达到目标稀疏度（如90%权重归零）或性能下降阈值。
</pre>
**剪枝粒度**

细粒度剪枝：逐个权重剪枝（如将小权重置零）。

结构化剪枝：移除整个通道（Channel）、层或注意力头（适合硬件加速）。

### 特征提取
升维：增强模型容量，适合捕获复杂特征。

降维：提高效率、防止过拟合，适合抽象高层语义。


## 2025-08-18

#### 梯度检查点
梯度检查点是一种显存优化技术，通过牺牲部分计算时间来显著减少训练时的显存占用

**核心思想是在反向传播时重新计算部分中间激活值，而非保存所有中间结果**（只保存部分关键层的激活值）

#### 动态梯度冻结

动态梯度冻结是一种计算优化技术，通过在训练过程中**选择性冻结（跳过）某些层的梯度计算**，减少不必要的反向传播开销
【
      **浅层特征**（如边缘检测器）可能早期就已收敛。
      
      **深层网络**的部分分支可能对当前任务贡献较小。
】

##### **RNN确实容易出现梯度爆炸问题**

梯度爆炸在RNN中发生的原因主要是：

**反向传播机制：**RNN在反向传播时需要沿着时间步骤链式求导。如果权重矩阵的特征值大于1，梯度会随着时间步的增加而指数级增长，最终导致梯度值变得极大。

**权重共享**：RNN在所有时间步共享相同的权重参数，这意味着同一个权重矩阵会被重复相乘多次，放大了梯度爆炸的效应。

**长序列问题**：序列越长，梯度传播的路径越长，累积的梯度变化就越剧烈。

## 2025-08-20

#### 梯度爆炸

**梯度裁剪（Gradient Clipping）** 这是最直接有效的方法。设置一个阈值（如5.0），当梯度范数超过这个值时，将梯度按比例缩放
**权重初始化**
使用Xavier或He初始化，保证权重矩阵的特征值在合理范围内，避免权重过大导致的梯度爆炸。

**权重正则化**
添加L1或L2正则化项约束权重大小，防止权重变得过大。

#### 梯度消失的解决方法

**LSTM和GRU架构**
这些门控RNN通过遗忘门、输入门等机制，创建"梯度高速公路"，让重要信息能够跨越多个时间步传播。

**残差连接**（Residual Connections）
在深层RNN中添加跳跃连接，让梯度可以直接传播到前面的层。

**更好的激活函数**
使用ReLU替代sigmoid/tanh，因为ReLU的导数在正值区域恒为1，不会造成梯度衰减。

### 通用解决方案
注意力机制（Attention）
让模型直接访问所有时间步的信息，避免信息在长序列传播中的损失。

Transformer架构
完全摒弃**递归结构，使用自注意力机制**，从根本上避免了梯度传播问题。

**批量归一化**
在RNN的每个时间步应用批量归一化，稳定梯度传播。


### GPU内存不足会导致训练变得很慢

**numpy2.0改动很大-不兼容的改动**   numpy==1.26.4  一般兼容新老

* `BatchNorm: 前层 > 后层
* 
* Dropout: 后层 > 前层
* 
* Weight Decay: 全局重要     --    **label_smoothing=0.1** ：  一种正则化技术-（作用于损失函数）
* 
* Gradient Clipping: 训练稳定性
* 
* Early Stopping: 防止过拟合`

## 2025-08-21

**混合精度训练 (AMP / autocast) 的副作用 (最可能)**

你使用了 torch.amp.autocast，它将许多计算从 float32 转换为 float16 以提高效率。float16 的数值范围远小于 float32。

场景: 在训练过程中，模型的权重可能逐渐增大。在 Epoch 52，当某个特定的输入数据批次通过网络时，某个中间层的激活值可能瞬间变得非常大，超出了 float16 的表示范围，导致上溢（overflow）变成 inf。

连锁反应: 一旦出现 inf，后续的计算（例如 inf - inf 或 0 * inf）就会产生 NaN，这个 NaN 会像病毒一样在网络中传播，最终污染整个输出。

**GradScaler 主要解决反向传播中的梯度下溢问题，但无法阻止前向传播中的激活值上溢。**


#### 权重正则化（Weight Regularization）是防止梯度上溢和过拟合

**L1正则化（Lasso）**

惩罚权重绝对值的和

**L2正则化（Ridge）**

惩罚权重平方

####  **课程学习：---  分阶段训练**

**参数越多越容易过拟合**

##### os.environ["CUDA_VISIBLE_DEVICES"] = '1' 后边导入gpu编号都是0

## 8 - 22

GPU的专用内存（VRAM）是高速内存，而共享内存（通常是系统主内存）是低速内存。
深度学习的计算和数据应尽可能完全放在VRAM中进行，尽量避免使用共享内存

**梯度裁剪，单纯增大学习率也不会显著改善训练速度**(因为梯度裁剪范围)

### 8 - 24

**几种学习率调度器**
ReduceLROnPlateau  :   依赖于一个高质量、稳定且与训练集同分布的验证集

Cosine Annealing   :   不依赖验证集-后期调优可能不足

**学习率预热**
它在训练的最初几个周期（或几个 step/iteration）内，将学习率从一个非常小的值（比如0或者 1e-8）线性地或非线性地增加到你设定的初始学习率

**最常见**   学习率预热+余弦退火

###### 学习率初始值设置

特别是使用 Adam 或 AdamW 优化器时，一个安全且有效的初始学习率范围是 1e-4 到 3e-3

### 8 - 27

**换个学习率调度器仍然可以续训（但可能要改保存的参数）**

