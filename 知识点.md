## 2025-7-2

1、pycharm 科学模式变成了   pycharm plot

2、进度条设置 leave   **运行完是否删除这个进度条**

3、 print 和 tqdm 有可能出现先实现顺序的问题

4、epoch少的时候的训练集的loss有可能低于val的loss，因为训练的时候有惩罚项 

5、epoch 先设置大一点，然后看tensorBoard观察曲线什么时候平稳。 

**（进阶）实现早停**：
 虽然你的代码里没有，但一个完整的训练流程通常会加入早停逻辑。你可以在验证循环后添加类似这样的逻辑：

#### 进阶：

**早停（Early Stopping）**: 判断验证损失是否不再下降，从而决定何时停止训练。

**模型选择（Model Selection）**: 比较不同模型的优劣。

**超参数调整（Hyperparameter Tuning）**: 根据验证损失来调整学习率等参数。



## 2025-07-03

**处理时序序列时：（填充+掩码+分桶）：** 这是处理变长序列最标准、最强大的方法。它能最大程度地保留数据中的宝贵信息。虽然实现起来比方案一稍微复杂一点，但几乎所有的深度学习框架（PyTorch, TensorFlow）都有现成的函数（如 `pad_sequence`）和成熟的教程来帮助你实现。这是最值得投入时间学习的正确方向。



远程控制软件是在**被控电脑本地抓取画面** → 编码 → 传输 → 控制端解码显示。

> 所以，被控端的**屏幕分辨率决**定了抓取的图像源大小（清晰度基础

**编码压缩会影响画质**

**远程协助画质 = 被控电脑分辨率 × 编码压缩效果 × 网络带宽 × 控制端缩放表现**

**产生公钥命令： ssh-keygen -t ed25519 -C "your_email@example.com"**

**git remote add origin git@github.com:your_username/your_repo.git**

**git push -u origin main**

git remote set-url origin git@github.com:your_username/your_repo.git

**git push**

## 2025-07-04

**MSFKE 创新点：**

1. **BranchAwareSEModule**

   * **分支感知的 SE 设计**：对每条频率分支分别做独立的通**道注意力（SE）**，并在分支间再做一次全局**重要性重标定**。
   * **阶段感知 (stage-aware)**：根据「early/mid/late」阶段，动态调整 Dropout 比例和不同频段的偏置 `freq_bias`，从而在训练**早期更关注全局低频、中期平衡、后期聚焦高频**细节。
   * **躯干 vs 肢体差异化**：`module_type='trunk'` 偏好低频，使用大卷积核；`module_type='limb'` 偏好高频，使用小卷积核并切换到 GELU 激活。

2. **TrunkSEModule & LimbSEModule**

   * **去全局池化的轻量化 SE**：用 1×1 卷积替代全局池化 + 全连接，直接在时序维度上的特征图里做压缩–扩张，计算更紧凑。
   * **定制化卷积**：Trunk 用宽感受野 (kernel\_size=5)，Limb 用深度可分离 (groups=channels) 卷积，分别强化全局与局部信息捕捉。

3. **NodeAwareMSFKE（节点感知的多尺度频域特征提取）**

   * **多尺度分支提取**：对每个节点并行应用一**组不同膨胀率（dilation）**的双卷积分支，形成多频段特征。
   * **节点专属 SE**：每个节点都配一对 `BranchAwareSEModule`（trunk/limb），实现 per-node 的多频融合与注意力加权。
   * **节点位置编码融合**：为每个节**点学习可训练 embedding**，并在 SE 输出后拼接到特征里，强化「关节身份」信息。
   * **阶段可变架构**：根据训练阶段 (`stage=early/mid/late`) 动态选取膨胀率列表及基础通道数，保证不同训练阶段对全局 vs 细节的侧重点。

4. **稀疏掩码（Mask）支持**

   * 虽未直接写出，但在高层调用中可引入 mask，将仅有的 6 个叶节点数据有效化，屏蔽其余 18 个全零通道，达到跳过无效计算、节省 FLOPs、加速收敛的目的。

### DFTFPE
### 1. 图时空卷积网络 (SpatioTemporalGCN)

1. **阶段感知的图结构选择**

   * 根据 `stage=early/mid/late` 动态切换不同的骨骼拓扑 (`Graph_B` vs `Graph_A`)、节点数（6 vs 24）和是否需要由 IMU → 全关节的映射层，兼顾训练早期**轻量化与中后期全骨骼建模**。
2. **可学习的边重要性 (Edge Importance)**

   * 在固定的邻接矩阵 `A` 上引入可训练参数 `edge_importance`，使模型能**自适应地微调骨骼关节间的消息传递强度**。
3. **双层图卷积 + 序列级残差**

   * 两层 `GraphConvBlock` 串联，每层内**部自带残差分支**，并在时序与节点维度上均做批量归一化，增强深度可训练性。
4. **统一时序–节点并行到串行处理**

   * 先用 GCN 在 `[B, T, N, C]` 上并行提取空间依赖，再 reshape→`TemporalConvBlock` 在 `[B, C·N, T]` 上做时间卷积，保证时空信息全面融合。

---

### 2. 非对称双向 GRU (AsymmetricBidirectionalGRU)

1. **窗口中心化滑动**

   * 对每个时间点构造一个以“当前帧”为中心的不对称窗口，**前向 GRU 覆盖过去更多帧，后向 GRU 聚焦未来较少帧**，更符合动作预测的因果性质。
2. **矢量化高性能实现**

   * 利用 `F.pad`+`unfold`一次性抽取所有滑窗，并在批次维度上并行跑前/后向 GRU，大幅提升对齐和吞吐。
3. **可调节的阶段超参**

   * 不同 `stage` 下动态设置窗口长度、当前帧索引、丢弃率和滑动步长，**为不同训练阶段提供粗→细、慢→快的时序建模策略**。

---

### 3. 自定义温度缩放多头注意力 (CustomMultiheadAttention)

1. **可控注意力“锐化”/“平滑”**

   * 在标准点积注意力里加入**温度参数** `temperature`，数值越高分布越平滑（early stage），越低分布越集中（late stage），让网络按阶段动态调整关注范围。
2. **纯 PyTorch 实现、Batch-First 优化**

   * 整段代码从投影到 reshape，再到 softmax/dropout，均基于 `batch_first=True`，与后续融合层无缝衔接。

---

### 4. 双流 Transformer 融合 (DSTFPE → DualStreamTransformerFusion)

1. **并行“躯干” vs “肢体”流**

   * `body_feats`（GCN 全局特征）和 `limb_feats`（GRU 局部特征）分别过**自注意力 → 交叉注意力**，保留双流特有语义。
2. **交叉融合门控**

   * 对每次交叉注意力输出，用小型门控网络学习“是保留自身流”还是“借用对方流”更多信息，实现自适应特征混合。
3. **阶段映射 → 融合温度**

   * 在 `DSTFPE` 顶层用字典把 `stage` 映射到注意力温度值，贯穿整个多层双流 Transformer，形成完整的“粗→细”训练节奏。

---


## 回归问题可以用到的图

1. **预测值 vs. 真实值 散点图**

2. ** 残差图**

3. **残差分布直方图、KDE\Q-Q图**

4. **特征相关性或重要性热力图**<训练阶段>

5. **网格热图**在二维特征空间中，用色块展示模型预测或误差大小<训练阶段>
